% Use this file for citations not found in the ACL Anthology (contained in 
%"anthology.bib").
@inproceedings{chemu,
  title={ChEMU: named entity recognition and event extraction of chemical reactions from patents},
  author={Nguyen, Dat Quoc and Zhai, Zenan and Yoshikawa, Hiyori and Fang, Biaoyan and Druckenbrodt, Christian and Thorne, Camilo and Hoessel, Ralph and Akhondi, Saber A and Cohn, Trevor and Baldwin, Timothy and others},
  booktitle={European Conference on Information Retrieval},
  pages={572--579},
  year={2020},
  organization={Springer}
}
@article{chem_article,
  title={Facile synthesis of NH-Free 5-(hetero) aryl-pyrrole-2-carboxylates by catalytic C--H borylation and Suzuki coupling},
  author={Kanwal, Saba and Ann, Noor-ul and Fatima, Saman and Emwas, Abdul-Hamid and Alazmi, Meshari and Gao, Xin and Ibrar, Maha and Saleem, Rahman Shah Zaib and Chotana, Ghayoor Abbas and others},
  journal={Molecules},
  volume={25},
  number={9},
  pages={2106},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{gin,
  title={How powerful are graph neural networks?},
  author={Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
  journal={arXiv preprint arXiv:1810.00826},
  year={2018}
}
@inproceedings{mmdl,
  title={Multimodal deep learning},
  author={Ngiam, Jiquan and Khosla, Aditya and Kim, Mingyu and Nam, Juhan and Lee, Honglak and Ng, Andrew Y},
  booktitle={ICML},
  year={2011}
}
@inproceedings{commonspace1,
  title={Multi Stage Common Vector Space for Multimodal Embeddings},
  author={Gopalakrishnan, Sabarish and Udaiyar, Premkumar and Sah, Shagan and Ptucha, Raymond},
  booktitle={2019 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)},
  pages={1--5},
  year={2019},
  organization={IEEE}
}
@article{kplug,
  title={K-PLUG: Knowledge-injected Pre-trained Language Model for Natural Language Understanding and Generation in E-Commerce},
  author={Xu, Song and Li, Haoran and Yuan, Peng and Wang, Yujia and Wu, Youzheng and He, Xiaodong and Liu, Ying and Zhou, Bowen},
  journal={arXiv preprint arXiv:2104.06960},
  year={2021}
}
@article{kadapter,
  title={K-adapter: Infusing knowledge into pre-trained models with adapters},
  author={Wang, Ruize and Tang, Duyu and Duan, Nan and Wei, Zhongyu and Huang, Xuanjing and Cao, Cuihong and Jiang, Daxin and Zhou, Ming and others},
  journal={arXiv preprint arXiv:2002.01808},
  year={2020}
}
@article{kepler,
  title={KEPLER: A unified model for knowledge embedding and pre-trained language representation},
  author={Wang, Xiaozhi and Gao, Tianyu and Zhu, Zhaocheng and Zhang, Zhengyan and Liu, Zhiyuan and Li, Juanzi and Tang, Jian},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={176--194},
  year={2021},
  publisher={MIT Press}
}
@article{kblstm,
  title={Leveraging knowledge bases in lstms for improving machine reading},
  author={Yang, Bishan and Mitchell, Tom},
  journal={arXiv preprint arXiv:1902.09091},
  year={2019}
}
@article{know4qa,
  title={Improving question answering with external knowledge},
  author={Pan, Xiaoman and Sun, Kai and Yu, Dian and Chen, Jianshu and Ji, Heng and Cardie, Claire and Yu, Dong},
  journal={arXiv preprint arXiv:1902.00993},
  year={2019}
}
@inproceedings{kbert,
  title={K-bert: Enabling language representation with knowledge graph},
  author={Liu, Weijie and Zhou, Peng and Zhao, Zhe and Wang, Zhiruo and Ju, Qi and Deng, Haotang and Wang, Ping},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={03},
  pages={2901--2908},
  year={2020}
}
@inproceedings{kg4ner,
  title={Knowledge-graph augmented word representations for named entity recognition},
  author={He, Qizhen and Wu, Liang and Yin, Yida and Cai, Heming},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={05},
  pages={7919--7926},
  year={2020}
}
@article{erica,
  title={ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning},
  author={Qin, Yujia and Lin, Yankai and Takanobu, Ryuichi and Liu, Zhiyuan and Li, Peng and Ji, Heng and Huang, Minlie and Sun, Maosong and Zhou, Jie},
  journal={arXiv preprint arXiv:2012.15022},
  year={2020}
}
@article{hyperbolic,
  title={Fine-grained entity typing in hyperbolic space},
  author={L{\'o}pez, Federico and Heinzerling, Benjamin and Strube, Michael},
  journal={arXiv preprint arXiv:1906.02505},
  year={2019}
}
@inproceedings{hierarchical_gcn,
  title={Fine-grained entity typing via hierarchical multi graph convolutional networks},
  author={Jin, Hailong and Hou, Lei and Li, Juanzi and Dong, Tiansi},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={4970--4979},
  year={2019}
}
@article{ultrafet,
  title={Ultra-fine entity typing},
  author={Choi, Eunsol and Levy, Omer and Choi, Yejin and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1807.04905},
  year={2018}
}
@article{biomedpp6,
  title={Improving biomedical named entity recognition with syntactic information},
  author={Tian, Yuanhe and Shen, Wang and Song, Yan and Xia, Fei and He, Min and Li, Kenli},
  journal={BMC bioinformatics},
  volume={21},
  number={1},
  pages={1--17},
  year={2020},
  publisher={BioMed Central}
}
@article{biomedpp5,
  title={Extracting chemical--protein relations using attention-based neural networks},
  author={Liu, Sijia and Shen, Feichen and Komandur Elayavilli, Ravikumar and Wang, Yanshan and Rastegar-Mojarad, Majid and Chaudhary, Vipin and Liu, Hongfang},
  journal={Database},
  volume={2018},
  year={2018},
  publisher={Oxford Academic}
}
@article{biomedpp4,
  title={Biomedical named entity recognition using deep neural networks with contextual information},
  author={Cho, Hyejin and Lee, Hyunju},
  journal={BMC bioinformatics},
  volume={20},
  number={1},
  pages={1--11},
  year={2019},
  publisher={Springer}
}
@article{biomedpp3,
  title={A neural joint model for entity and relation extraction from biomedical text},
  author={Li, Fei and Zhang, Meishan and Fu, Guohong and Ji, Donghong},
  journal={BMC bioinformatics},
  volume={18},
  number={1},
  pages={1--11},
  year={2017},
  publisher={BioMed Central}
}
@inproceedings{biomedpp2,
  title={Biomedical event extraction based on knowledge-driven tree-LSTM},
  author={Li, Diya and Huang, Lifu and Ji, Heng and Han, Jiawei},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={1421--1430},
  year={2019}
}
@inproceedings{biomedpp1,
  title={Joint inference for knowledge extraction from biomedical literature},
  author={Poon, Hoifung and Vanderwende, Lucy},
  booktitle={Human language technologies: the 2010 annual conference of the North American chapter of the association for computational linguistics},
  pages={813--821},
  year={2010}
}


@inproceedings{LiACL2020,
    title     = {Cross-media Structured Common Space for Multimedia Event Extraction},
    author    = {Li, Manling and Zareian, Alireza and Zeng, Qi and Whitehead, Spencer and Lu, Di and Ji, Heng and Chang, Shih-Fu},
    year      = {2020},
    booktitle = {Proc. The 58th Annual Meeting of the Association for Computational Linguistics (ACL2020)}
}


@article{transformer,
	title={Attention is all you need},
	author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
	journal={arXiv preprint arXiv:1706.03762},
	year={2017}
}
@inproceedings{brat,
	title={BRAT: a web-based tool for NLP-assisted text annotation},
	author={Stenetorp, Pontus and Pyysalo, Sampo and Topi{\'c}, Goran and Ohta, Tomoko and Ananiadou, Sophia and Tsujii, Junâ€™ichi},
	booktitle={Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics},
	pages={102--107},
	year={2012}
}
@article{oscar4,
	title={OSCAR4: a flexible architecture for chemical text-mining},
	author={Jessop, David M and Adams, Sam E and Willighagen, Egon L and Hawizy, Lezan and Murray-Rust, Peter},
	journal={Journal of cheminformatics},
	volume={3},
	number={1},
	pages={1--12},
	year={2011},
	publisher={BioMed Central}
}

@article{biomedie,
  title={Learning for biomedical information extraction: Methodological review of recent advances},
  author={Liu, Feifan and Chen, Jinying and Jagannatha, Abhyuday and Yu, Hong},
  journal={arXiv preprint arXiv:1606.07993},
  year={2016}
}
@inproceedings{eetreelstm,
  title={Biomedical event extraction based on knowledge-driven tree-LSTM},
  author={Li, Diya and Huang, Lifu and Ji, Heng and Han, Jiawei},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={1421--1430},
  year={2019}
}

@inproceedings{danmm,
  title={Dual attention networks for multimodal reasoning and matching},
  author={Nam, Hyeonseob and Ha, Jung-Woo and Kim, Jeonghee},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={299--307},
  year={2017}
}
@inproceedings{ye2019cross,
  title={Cross-modal self-attention network for referring image segmentation},
  author={Ye, Linwei and Rochan, Mrigank and Liu, Zhi and Wang, Yang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10502--10511},
  year={2019}
}
@article{sim_filter,
  title={Similarity Reasoning and Filtration for Image-Text Matching},
  author={Diao, Haiwen and Zhang, Ying and Ma, Lin and Lu, Huchuan},
  journal={arXiv preprint arXiv:2101.01368},
  year={2021}
}
@inproceedings{wei2020multi,
  title={Multi-modality cross attention network for image and sentence matching},
  author={Wei, Xi and Zhang, Tianzhu and Li, Yan and Zhang, Yongdong and Wu, Feng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10941--10950},
  year={2020}
}
@article{fet_el,
  title={Improving fine-grained entity typing with entity linking},
  author={Dai, Hongliang and Du, Donghong and Li, Xin and Song, Yangqiu},
  journal={arXiv preprint arXiv:1909.12079},
  year={2019}
}

@article{label_bias,
  title={Imposing label-relational inductive bias for extremely fine-grained entity typing},
  author={Xiong, Wenhan and Wu, Jiawei and Lei, Deren and Yu, Mo and Chang, Shiyu and Guo, Xiaoxiao and Wang, William Yang},
  journal={arXiv preprint arXiv:1903.02591},
  year={2019}
}

@article{e2ecoref,
	title={End-to-end neural coreference resolution},
	author={Lee, Kenton and He, Luheng and Lewis, Mike and Zettlemoyer, Luke},
	journal={arXiv preprint arXiv:1707.07045},
	year={2017}
}
@inproceedings{cmsa,
	title={Cross-modal self-attention network for referring image segmentation},
	author={Ye, Linwei and Rochan, Mrigank and Liu, Zhi and Wang, Yang},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={10502--10511},
	year={2019}
}
@article{huggingface,
	title={HuggingFace's Transformers: State-of-the-art natural language processing},
	author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
	journal={arXiv preprint arXiv:1910.03771},
	year={2019}
}
@article{pytorch,
	title={Pytorch: An imperative style, high-performance deep learning library},
	author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
	journal={arXiv preprint arXiv:1912.01703},
	year={2019}
}
@inproceedings{lin2019attentive,
	title={An attentive fine-grained entity typing model with latent type representation},
	author={Lin, Ying and Ji, Heng},
	booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
	pages={6198--6203},
	year={2019}
}

@article{biobert,
	title={BioBERT: a pre-trained biomedical language representation model for biomedical text mining},
	author={Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
	journal={Bioinformatics},
	volume={36},
	number={4},
	pages={1234--1240},
	year={2020},
	publisher={Oxford University Press}
}
@article{scibert,
	title={SciBERT: A pretrained language model for scientific text},
	author={Beltagy, Iz and Lo, Kyle and Cohan, Arman},
	journal={arXiv preprint arXiv:1903.10676},
	year={2019}
}

@article{dygie,
	title={A general framework for information extraction using dynamic span graphs},
	author={Luan, Yi and Wadden, Dave and He, Luheng and Shah, Amy and Ostendorf, Mari and Hajishirzi, Hannaneh},
	journal={arXiv preprint arXiv:1904.03296},
	year={2019}
}
@article{bert,
	title={Bert: Pre-training of deep bidirectional transformers for language understanding},
	author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	journal={arXiv preprint arXiv:1810.04805},
	year={2018}
}
@article{visualbert,
	title={Visualbert: A simple and performant baseline for vision and language},
	author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
	journal={arXiv preprint arXiv:1908.03557},
	year={2019}
}

@article{vlbert,
	title={Vl-bert: Pre-training of generic visual-linguistic representations},
	author={Su, Weijie and Zhu, Xizhou and Cao, Yue and Li, Bin and Lu, Lewei and Wei, Furu and Dai, Jifeng},
	journal={arXiv preprint arXiv:1908.08530},
	year={2019}
}

@article{luke,
	title={LUKE: deep contextualized entity representations with entity-aware 
	self-attention},
	author={Yamada, Ikuya and Asai, Akari and Shindo, Hiroyuki and Takeda, 
	Hideaki and Matsumoto, Yuji},
	journal={arXiv preprint arXiv:2010.01057},
	year={2020}
}

@article{ernie,
	title={ERNIE: Enhanced language representation with informative entities},
	author={Zhang, Zhengyan and Han, Xu and Liu, Zhiyuan and Jiang, Xin and 
	Sun, Maosong and Liu, Qun},
	journal={arXiv preprint arXiv:1905.07129},
	year={2019}
}
@article{knowbert,
	title={Knowledge enhanced contextual word representations},
	author={Peters, Matthew E and Neumann, Mark and Logan IV, Robert L and 
	Schwartz, Roy and Joshi, Vidur and Singh, Sameer and Smith, Noah A},
	journal={arXiv preprint arXiv:1909.04164},
	year={2019}
}

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}
